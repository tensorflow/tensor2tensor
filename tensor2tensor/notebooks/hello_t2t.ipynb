{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "s19ucTii_wYb"
      },
      "outputs": [],
      "source": [
        "# Copyright 2017 Google LLC.\n",
        "\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "OPGni6fuvoTj"
      },
      "outputs": [],
      "source": [
        "# Install deps\n",
        "!pip install -q \"tensor2tensor-dev==1.3.1.dev5\" tf-nightly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "oILRLCWN_16u"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tensor2tensor import problems\n",
        "from tensor2tensor.utils import t2t_model\n",
        "from tensor2tensor.utils import trainer_utils\n",
        "from tensor2tensor.utils import registry\n",
        "from tensor2tensor.utils import metrics\n",
        "\n",
        "# Enable TF Eager execution\n",
        "from tensorflow.contrib.eager.python import tfe\n",
        "tfe.enable_eager_execution()\n",
        "\n",
        "# Other setup\n",
        "Modes = tf.estimator.ModeKeys\n",
        "\n",
        "# Setup some directories\n",
        "data_dir = os.path.expanduser(\"~/t2t/data\")\n",
        "tmp_dir = os.path.expanduser(\"~/t2t/tmp\")\n",
        "train_dir = os.path.expanduser(\"~/t2t/train\")\n",
        "checkpoint_dir = os.path.expanduser(\"~/t2t/checkpoints\")\n",
        "tf.gfile.MakeDirs(data_dir)\n",
        "tf.gfile.MakeDirs(tmp_dir)\n",
        "tf.gfile.MakeDirs(train_dir)\n",
        "tf.gfile.MakeDirs(checkpoint_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gXL7_bVH49Kl"
      },
      "source": [
        "# Translate from English to French with a pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "Q2CYCYjZTlZs"
      },
      "outputs": [],
      "source": [
        "# Translation\n",
        "enfr_problem = registry.problem(\"translate_enfr_wmt_small32k\")\n",
        "enfr_problem.generate_data(data_dir, tmp_dir) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "g2aQW7Z6TOEu"
      },
      "outputs": [],
      "source": [
        "example = tfe.Iterator(enfr_problem.dataset(Modes.TRAIN, data_dir)).next()\n",
        "inputs = [int(x) for x in example[\"inputs\"].numpy()] # Cast to ints.\n",
        "targets = [int(x) for x in example[\"targets\"].numpy()] # Cast to ints.\n",
        "\n",
        "encoders = enfr_problem.feature_encoders(data_dir)\n",
        "def decode(integers):\n",
        "  samples = encoders[\"inputs\"].decode(np.squeeze(integers))\n",
        "  return samples[:samples.find(\"\u003cEOS\u003e\")]\n",
        "\n",
        "# Example inputs as int-tensor.\n",
        "print(\"Inputs, encoded:\")\n",
        "print(inputs)\n",
        "print(\"Inputs, decoded:\")\n",
        "# Example inputs as a sentence.\n",
        "print(decode(inputs))\n",
        "# Example targets as int-tensor.\n",
        "print(\"Targets, encoded:\")\n",
        "print(targets)\n",
        "# Example targets as a sentence.\n",
        "print(\"Targets, decoded:\")\n",
        "print(decode(targets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "9l6hDQbrRUYV"
      },
      "outputs": [],
      "source": [
        "# Create hparams and the T2TModel object.\n",
        "model_name = \"transformer\"\n",
        "hparams_set = \"transformer_base\"\n",
        "\n",
        "hparams = trainer_utils.create_hparams(hparams_set, data_dir)\n",
        "hparams.use_eager_mode = True\n",
        "trainer_utils.add_problem_hparams(hparams, \"translate_enfr_wmt32k\")\n",
        "\n",
        "# NOTE: Only create the model once when restoring from a checkpoint; it's a\n",
        "# Layer and so subsequent instantiations will have different variable scopes\n",
        "# that will not match the checkpoint.\n",
        "model = registry.model(model_name)(hparams, Modes.PREDICT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "FEwNUVlMYOJi"
      },
      "outputs": [],
      "source": [
        "# Copy the pretrained checkpoint locally\n",
        "gs_ckpt_dir = \"gs://tensor2tensor-checkpoints/\"\n",
        "ckpt_name = \"transformer_enfr_test\"\n",
        "gs_ckpt = os.path.join(gs_ckpt_dir, ckpt_name)\n",
        "local_ckpt = os.path.join(checkpoint_dir, ckpt_name)\n",
        "!gsutil -q cp -R {gs_ckpt} {local_ckpt}\n",
        "ckpt_path = tf.train.latest_checkpoint(local_ckpt)\n",
        "ckpt_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "3O-8E9d6TtuJ"
      },
      "outputs": [],
      "source": [
        "# Restore and translate!\n",
        "\n",
        "def encode(input_str):\n",
        "  # Encode from raw string to ints using problem encoders.\n",
        "  inputs = encoders[\"inputs\"].encode(input_str) + [1]  # add EOS id\n",
        "  batch_inputs = tf.reshape(inputs, [1, -1, 1, 1])  # Make it 4D.\n",
        "  # TODO: rm target_space_id\n",
        "  features_dict = {\"inputs\": batch_inputs,\n",
        "                   \"target_space_id\": tf.constant(hparams.problems[0].target_space_id)}\n",
        "  return features_dict\n",
        "\n",
        "# Input to the decoder.\n",
        "inputs = \"This is a cat.\"\n",
        "\n",
        "store = tfe.EagerVariableStore()\n",
        "# Restore from checkpoint and run inference\n",
        "with store.as_default():\n",
        "  with tfe.restore_variables_on_create(ckpt_path):\n",
        "    samples = model.infer(encode(inputs), beam_size=1)\n",
        "\n",
        "print(\"Inputs: %s\" % inputs)\n",
        "print(\"Outputs: %s\" % decode(samples))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i7BZuO7T5BB4"
      },
      "source": [
        "# Train a custom model on MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "RYDMO4zArgkz"
      },
      "outputs": [],
      "source": [
        "# Lots of problems available\n",
        "problems.available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "JKc2uSk6WX5e"
      },
      "outputs": [],
      "source": [
        "# Create the MNIST problem and generate the data\n",
        "\n",
        "mnist_problem = problems.problem(\"image_mnist\")\n",
        "# Generate data\n",
        "mnist_problem.generate_data(data_dir, tmp_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "VW6HCRANFPYV"
      },
      "outputs": [],
      "source": [
        "# Get the tf.data.Dataset from Problem.dataset\n",
        "mnist_example = tfe.Iterator(mnist_problem.dataset(Modes.TRAIN, data_dir)).next()\n",
        "image = mnist_example[\"inputs\"]\n",
        "label = mnist_example[\"targets\"]\n",
        "\n",
        "plt.imshow(image.numpy()[:, :, 0].astype(np.float32), cmap=plt.get_cmap('gray'))\n",
        "print(\"Label: %d\" % label.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "WkFUEs7ZOA79"
      },
      "outputs": [],
      "source": [
        "# Lots of models available\n",
        "registry.list_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "-H25oG91YQj3"
      },
      "outputs": [],
      "source": [
        "# Create your own model\n",
        "\n",
        "class MySimpleModel(t2t_model.T2TModel):\n",
        "\n",
        "  def model_fn_body(self, features):\n",
        "    inputs = features[\"inputs\"]\n",
        "    filters = self.hparams.hidden_size\n",
        "    h1 = tf.layers.conv2d(inputs, filters,\n",
        "                          kernel_size=(5, 5), strides=(2, 2))\n",
        "    h2 = tf.layers.conv2d(tf.nn.relu(h1), filters,\n",
        "                          kernel_size=(5, 5), strides=(2, 2))\n",
        "    return tf.layers.conv2d(tf.nn.relu(h2), filters,\n",
        "                            kernel_size=(3, 3))\n",
        "\n",
        "hparams = trainer_utils.create_hparams(\"basic_1\", data_dir)\n",
        "hparams.hidden_size = 64\n",
        "hparams.use_eager_mode = True\n",
        "trainer_utils.add_problem_hparams(hparams, \"image_mnist\")\n",
        "model = MySimpleModel(hparams, Modes.TRAIN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "AWVd2I7PYz6H"
      },
      "outputs": [],
      "source": [
        "# Train\n",
        "store = tfe.EagerVariableStore()\n",
        "optimizer = tf.train.AdamOptimizer()\n",
        "\n",
        "# In Eager mode, opt.minimize must be passed a function that produces the loss\n",
        "def loss_function(features):\n",
        "  _, losses = model(features)\n",
        "  return losses[\"training\"]\n",
        "\n",
        "tfe_loss_fn = tfe.implicit_value_and_gradients(loss_function)\n",
        "\n",
        "NUM_STEPS = 500\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# Repeat and batch the data\n",
        "mnist_train_dataset = mnist_problem.dataset(Modes.TRAIN, data_dir)\n",
        "mnist_train_dataset = mnist_train_dataset.repeat(None).batch(BATCH_SIZE)\n",
        "\n",
        "# Training loop\n",
        "for count, example in enumerate(tfe.Iterator(mnist_train_dataset)):\n",
        "  if count \u003e= NUM_STEPS:\n",
        "    break\n",
        "\n",
        "  example[\"targets\"] = tf.reshape(example[\"targets\"], [BATCH_SIZE, 1, 1, 1])  # Make it 4D.\n",
        "  loss, gv = tfe_loss_fn(example)\n",
        "  optimizer.apply_gradients(gv)\n",
        "  if count % 50 == 0:\n",
        "    print(\"Step: %d, Loss: %.3f\" % (count, loss.numpy()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "CIFlkiVOd8jO"
      },
      "outputs": [],
      "source": [
        "model.set_mode(Modes.EVAL)\n",
        "mnist_eval_dataset = mnist_problem.dataset(Modes.EVAL, data_dir)\n",
        "all_perplexities = []\n",
        "all_accuracies = []\n",
        "for count, example in enumerate(tfe.Iterator(mnist_eval_dataset)):\n",
        "  if count \u003e= 100:\n",
        "    break\n",
        "\n",
        "  batch_inputs = tf.reshape(example[\"inputs\"], [1, 28, 28, 3])  # Make it 4D.\n",
        "  batch_targets = tf.reshape(example[\"targets\"], [1, 1, 1, 1])  # Make it 4D.\n",
        "  features = {\"inputs\": batch_inputs, \"targets\": batch_targets}\n",
        "\n",
        "  # Call the model.\n",
        "  with store.as_default():\n",
        "    predictions, _ = model(features)\n",
        "\n",
        "  # Calculate and append the metrics\n",
        "  all_perplexities.extend(metrics.padded_neg_log_perplexity(predictions, features[\"targets\"]))\n",
        "  all_accuracies.extend(metrics.padded_accuracy(predictions, features[\"targets\"]))\n",
        "\n",
        "# Print out metrics on the dataset\n",
        "print(\"Accuracy: %.2f\" % tf.reduce_mean(tf.concat(all_accuracies, axis=1)).numpy())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "default_view": {},
      "name": "T2T with TF Eager",
      "provenance": [],
      "version": "0.3.2",
      "views": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
