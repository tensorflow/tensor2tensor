{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T2T with TF Eager",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "s19ucTii_wYb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "source": [
        "# Copyright 2017 Google LLC.\n",
        "\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "cell_type": "code",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OPGni6fuvoTj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "source": [
        "# Install deps\n",
        "!pip install -q \"tensor2tensor-dev==1.3.1.dev7\" tf-nightly"
      ],
      "cell_type": "code",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oILRLCWN_16u",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tensor2tensor import problems\n",
        "from tensor2tensor.utils import t2t_model\n",
        "from tensor2tensor.utils import trainer_utils\n",
        "from tensor2tensor.utils import registry\n",
        "from tensor2tensor.utils import metrics\n",
        "\n",
        "# Enable TF Eager execution\n",
        "from tensorflow.contrib.eager.python import tfe\n",
        "tfe.enable_eager_execution()\n",
        "\n",
        "# Other setup\n",
        "Modes = tf.estimator.ModeKeys\n",
        "\n",
        "# Setup some directories\n",
        "data_dir = os.path.expanduser(\"~/t2t/data\")\n",
        "tmp_dir = os.path.expanduser(\"~/t2t/tmp\")\n",
        "train_dir = os.path.expanduser(\"~/t2t/train\")\n",
        "checkpoint_dir = os.path.expanduser(\"~/t2t/checkpoints\")\n",
        "tf.gfile.MakeDirs(data_dir)\n",
        "tf.gfile.MakeDirs(tmp_dir)\n",
        "tf.gfile.MakeDirs(train_dir)\n",
        "tf.gfile.MakeDirs(checkpoint_dir)\n",
        "gs_data_dir = \"gs://tensor2tensor-data\"\n",
        "gs_ckpt_dir = \"gs://tensor2tensor-checkpoints/\""
      ],
      "cell_type": "code",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gXL7_bVH49Kl",
        "colab_type": "text"
      },
      "source": [
        "# Translate from English to German with a pre-trained model"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {
        "id": "Q2CYCYjZTlZs",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 2
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b13d53a3-feba-4d74-fc1e-951bef99ecb0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1512165746671,
          "user_tz": 480,
          "elapsed": 2799,
          "user": {
            "displayName": "Ryan Sepassi",
            "photoUrl": "//lh4.googleusercontent.com/-dcHmhQy1Y2A/AAAAAAAAAAI/AAAAAAAABEw/if_k14yF4KI/s50-c-k-no/photo.jpg",
            "userId": "107877449274830904926"
          }
        }
      },
      "source": [
        "# Translation\n",
        "ende_problem = registry.problem(\"translate_ende_wmt32k\")\n",
        "\n",
        "# Copy the vocab file locally\n",
        "vocab_file = os.path.join(gs_data_dir, \"vocab.ende.32768\")\n",
        "!gsutil cp {vocab_file} {data_dir}"
      ],
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://tensor2tensor-data/vocab.ende.32768...\n",
            "/ [1 files][316.4 KiB/316.4 KiB]                                                \n",
            "Operation completed over 1 objects/316.4 KiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EB4MP7_y_SuQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "source": [
        "encoders = ende_problem.feature_encoders(data_dir)\n",
        "\n",
        "def encode(input_str):\n",
        "  \"\"\"Input str to features dict, ready for inference\"\"\"\n",
        "  inputs = encoders[\"inputs\"].encode(input_str) + [1]  # add EOS id\n",
        "  batch_inputs = tf.reshape(inputs, [1, -1, 1])  # Make it 3D.\n",
        "  return {\"inputs\": batch_inputs}\n",
        "\n",
        "def decode(integers):\n",
        "  \"\"\"List of ints to str\"\"\"\n",
        "  integers = list(np.squeeze(integers))\n",
        "  if 1 in integers:\n",
        "    integers = integers[:integers.index(1)]\n",
        "  return encoders[\"inputs\"].decode(np.squeeze(integers))"
      ],
      "cell_type": "code",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g2aQW7Z6TOEu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "source": [
        "# # Generate and view the data\n",
        "# # This cell is commented out because data generation can take hours\n",
        "\n",
        "# ende_problem.generate_data(data_dir, tmp_dir)\n",
        "# example = tfe.Iterator(ende_problem.dataset(Modes.TRAIN, data_dir)).next()\n",
        "# inputs = [int(x) for x in example[\"inputs\"].numpy()] # Cast to ints.\n",
        "# targets = [int(x) for x in example[\"targets\"].numpy()] # Cast to ints.\n",
        "\n",
        "\n",
        "\n",
        "# # Example inputs as int-tensor.\n",
        "# print(\"Inputs, encoded:\")\n",
        "# print(inputs)\n",
        "# print(\"Inputs, decoded:\")\n",
        "# # Example inputs as a sentence.\n",
        "# print(decode(inputs))\n",
        "# # Example targets as int-tensor.\n",
        "# print(\"Targets, encoded:\")\n",
        "# print(targets)\n",
        "# # Example targets as a sentence.\n",
        "# print(\"Targets, decoded:\")\n",
        "# print(decode(targets))"
      ],
      "cell_type": "code",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9l6hDQbrRUYV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "source": [
        "# Create hparams and the T2TModel object.\n",
        "model_name = \"transformer\"\n",
        "hparams_set = \"transformer_base\"\n",
        "\n",
        "hparams = trainer_utils.create_hparams(hparams_set, data_dir)\n",
        "trainer_utils.add_problem_hparams(hparams, \"translate_ende_wmt32k\")\n",
        "\n",
        "# NOTE: Only create the model once when restoring from a checkpoint; it's a\n",
        "# Layer and so subsequent instantiations will have different variable scopes\n",
        "# that will not match the checkpoint.\n",
        "translate_model = registry.model(model_name)(hparams, Modes.PREDICT)"
      ],
      "cell_type": "code",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FEwNUVlMYOJi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc15a59a-7ea7-4baa-85c1-2a94528eb157",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1512165760778,
          "user_tz": 480,
          "elapsed": 12527,
          "user": {
            "displayName": "Ryan Sepassi",
            "photoUrl": "//lh4.googleusercontent.com/-dcHmhQy1Y2A/AAAAAAAAAAI/AAAAAAAABEw/if_k14yF4KI/s50-c-k-no/photo.jpg",
            "userId": "107877449274830904926"
          }
        }
      },
      "source": [
        "# Copy the pretrained checkpoint locally\n",
        "ckpt_name = \"transformer_ende_test\"\n",
        "gs_ckpt = os.path.join(gs_ckpt_dir, ckpt_name)\n",
        "!gsutil -q cp -R {gs_ckpt} {checkpoint_dir}\n",
        "ckpt_path = tf.train.latest_checkpoint(os.path.join(checkpoint_dir, ckpt_name))\n",
        "ckpt_path"
      ],
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "u'/content/t2t/checkpoints/transformer_ende_test/model.ckpt-350855'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "3O-8E9d6TtuJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 3
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "24231c95-99cb-421b-d961-5a21322be945",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1512165773424,
          "user_tz": 480,
          "elapsed": 12593,
          "user": {
            "displayName": "Ryan Sepassi",
            "photoUrl": "//lh4.googleusercontent.com/-dcHmhQy1Y2A/AAAAAAAAAAI/AAAAAAAABEw/if_k14yF4KI/s50-c-k-no/photo.jpg",
            "userId": "107877449274830904926"
          }
        }
      },
      "source": [
        "# Restore and translate!\n",
        "\n",
        "def translate(inputs):\n",
        "  encoded_inputs = encode(inputs)\n",
        "  with tfe.restore_variables_on_create(ckpt_path):\n",
        "    model_output = translate_model.infer(encoded_inputs)\n",
        "  return decode(model_output)\n",
        "\n",
        "inputs = \"This is a cat.\"\n",
        "outputs = translate(inputs)\n",
        "\n",
        "print(\"Inputs: %s\" % inputs)\n",
        "print(\"Outputs: %s\" % outputs)"
      ],
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Greedy Decoding\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/common_layers.py:487: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "Inputs: This is a cat.\n",
            "Outputs: Das ist eine Katze.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i7BZuO7T5BB4",
        "colab_type": "text"
      },
      "source": [
        "# Train a custom model on MNIST"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {
        "id": "RYDMO4zArgkz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 1224
        },
        "outputId": "3b62dff4-7bfa-436e-a9f5-ecf66616e93a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1512165773875,
          "user_tz": 480,
          "elapsed": 423,
          "user": {
            "displayName": "Ryan Sepassi",
            "photoUrl": "//lh4.googleusercontent.com/-dcHmhQy1Y2A/AAAAAAAAAAI/AAAAAAAABEw/if_k14yF4KI/s50-c-k-no/photo.jpg",
            "userId": "107877449274830904926"
          }
        }
      },
      "source": [
        "# Lots of problems available\n",
        "problems.available()"
      ],
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['algorithmic_addition_binary40',\n",
              " 'algorithmic_addition_decimal40',\n",
              " 'algorithmic_cipher_shift200',\n",
              " 'algorithmic_cipher_shift5',\n",
              " 'algorithmic_cipher_vigenere200',\n",
              " 'algorithmic_cipher_vigenere5',\n",
              " 'algorithmic_identity_binary40',\n",
              " 'algorithmic_identity_decimal40',\n",
              " 'algorithmic_multiplication_binary40',\n",
              " 'algorithmic_multiplication_decimal40',\n",
              " 'algorithmic_reverse_binary40',\n",
              " 'algorithmic_reverse_binary40_test',\n",
              " 'algorithmic_reverse_decimal40',\n",
              " 'algorithmic_reverse_nlplike32k',\n",
              " 'algorithmic_reverse_nlplike8k',\n",
              " 'algorithmic_shift_decimal40',\n",
              " 'audio_timit_characters_tune',\n",
              " 'audio_timit_tokens8k_test',\n",
              " 'audio_timit_tokens8k_tune',\n",
              " 'image_celeba_tune',\n",
              " 'image_cifar10',\n",
              " 'image_cifar10_plain',\n",
              " 'image_cifar10_plain8',\n",
              " 'image_cifar10_tune',\n",
              " 'image_fsns',\n",
              " 'image_imagenet',\n",
              " 'image_imagenet224',\n",
              " 'image_imagenet32',\n",
              " 'image_imagenet64',\n",
              " 'image_mnist',\n",
              " 'image_mnist_tune',\n",
              " 'image_ms_coco_characters',\n",
              " 'image_ms_coco_tokens32k',\n",
              " 'image_ms_coco_tokens8k',\n",
              " 'img2img_cifar10',\n",
              " 'img2img_imagenet',\n",
              " 'languagemodel_lm1b32k',\n",
              " 'languagemodel_lm1b8k_packed',\n",
              " 'languagemodel_lm1b_characters',\n",
              " 'languagemodel_ptb10k',\n",
              " 'languagemodel_ptb_characters',\n",
              " 'languagemodel_wiki_full32k',\n",
              " 'languagemodel_wiki_scramble128',\n",
              " 'languagemodel_wiki_scramble1k50',\n",
              " 'languagemodel_wiki_scramble8k50',\n",
              " 'librispeech',\n",
              " 'multinli_matched',\n",
              " 'multinli_mismatched',\n",
              " 'ocr_test',\n",
              " 'parsing_english_ptb16k',\n",
              " 'parsing_english_ptb8k',\n",
              " 'parsing_icelandic16k',\n",
              " 'programming_desc2code_cpp',\n",
              " 'programming_desc2code_py',\n",
              " 'sentiment_imdb',\n",
              " 'summarize_cnn_dailymail32k',\n",
              " 'translate_encs_wmt32k',\n",
              " 'translate_encs_wmt_characters',\n",
              " 'translate_ende_wmt32k',\n",
              " 'translate_ende_wmt32k_packed',\n",
              " 'translate_ende_wmt8k',\n",
              " 'translate_ende_wmt_bpe32k',\n",
              " 'translate_ende_wmt_characters',\n",
              " 'translate_enfr_wmt32k',\n",
              " 'translate_enfr_wmt8k',\n",
              " 'translate_enfr_wmt_characters',\n",
              " 'translate_enfr_wmt_small32k',\n",
              " 'translate_enfr_wmt_small8k',\n",
              " 'translate_enfr_wmt_small_characters',\n",
              " 'translate_enmk_setimes32k',\n",
              " 'translate_enzh_wmt8k']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "JKc2uSk6WX5e",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 3
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f9fa17c1-ed3f-474e-8bd8-f764c3b00000",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1512165774930,
          "user_tz": 480,
          "elapsed": 977,
          "user": {
            "displayName": "Ryan Sepassi",
            "photoUrl": "//lh4.googleusercontent.com/-dcHmhQy1Y2A/AAAAAAAAAAI/AAAAAAAABEw/if_k14yF4KI/s50-c-k-no/photo.jpg",
            "userId": "107877449274830904926"
          }
        }
      },
      "source": [
        "# Create the MNIST problem and generate the data\n",
        "\n",
        "mnist_problem = problems.problem(\"image_mnist\")\n",
        "# Generate data\n",
        "mnist_problem.generate_data(data_dir, tmp_dir)"
      ],
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Not downloading, file already found: /content/t2t/tmp/train-images-idx3-ubyte.gz\n",
            "INFO:tensorflow:Not downloading, file already found: /content/t2t/tmp/train-labels-idx1-ubyte.gz\n",
            "INFO:tensorflow:Not downloading, file already found: /content/t2t/tmp/t10k-images-idx3-ubyte.gz\n",
            "INFO:tensorflow:Not downloading, file already found: /content/t2t/tmp/t10k-labels-idx1-ubyte.gz\n",
            "INFO:tensorflow:Not downloading, file already found: /content/t2t/tmp/train-images-idx3-ubyte.gz\n",
            "INFO:tensorflow:Not downloading, file already found: /content/t2t/tmp/train-labels-idx1-ubyte.gz\n",
            "INFO:tensorflow:Not downloading, file already found: /content/t2t/tmp/t10k-images-idx3-ubyte.gz\n",
            "INFO:tensorflow:Not downloading, file already found: /content/t2t/tmp/t10k-labels-idx1-ubyte.gz\n",
            "INFO:tensorflow:Skipping generator because outputs files exist\n",
            "INFO:tensorflow:Skipping generator because outputs files exist\n",
            "INFO:tensorflow:Skipping shuffle because output files exist\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VW6HCRANFPYV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 2
            },
            {
              "item_id": 3
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "93dea49c-dbca-4856-998f-8bcbb621abea",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1512165775597,
          "user_tz": 480,
          "elapsed": 622,
          "user": {
            "displayName": "Ryan Sepassi",
            "photoUrl": "//lh4.googleusercontent.com/-dcHmhQy1Y2A/AAAAAAAAAAI/AAAAAAAABEw/if_k14yF4KI/s50-c-k-no/photo.jpg",
            "userId": "107877449274830904926"
          }
        }
      },
      "source": [
        "# Get the tf.data.Dataset from Problem.dataset\n",
        "mnist_example = tfe.Iterator(mnist_problem.dataset(Modes.TRAIN, data_dir)).next()\n",
        "image = mnist_example[\"inputs\"]\n",
        "label = mnist_example[\"targets\"]\n",
        "\n",
        "plt.imshow(image.numpy()[:, :, 0].astype(np.float32), cmap=plt.get_cmap('gray'))\n",
        "print(\"Label: %d\" % label.numpy())"
      ],
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reading data files from /content/t2t/data/image_mnist-train*\n",
            "Label: 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAaEJQAYEJYAYEBYAoABYQkABv8HkbgWVGnLsmMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f4899f96d90>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "WkFUEs7ZOA79",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "3d0c50f2-9c18-4d4b-8455-1aabe9e28190",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1512165775887,
          "user_tz": 480,
          "elapsed": 242,
          "user": {
            "displayName": "Ryan Sepassi",
            "photoUrl": "//lh4.googleusercontent.com/-dcHmhQy1Y2A/AAAAAAAAAAI/AAAAAAAABEw/if_k14yF4KI/s50-c-k-no/photo.jpg",
            "userId": "107877449274830904926"
          }
        }
      },
      "source": [
        "# Lots of models available\n",
        "registry.list_models()"
      ],
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['resnet50',\n",
              " 'lstm_seq2seq',\n",
              " 'transformer_encoder',\n",
              " 'attention_lm',\n",
              " 'vanilla_gan',\n",
              " 'transformer',\n",
              " 'gene_expression_conv',\n",
              " 'transformer_moe',\n",
              " 'attention_lm_moe',\n",
              " 'transformer_revnet',\n",
              " 'lstm_seq2seq_attention',\n",
              " 'shake_shake',\n",
              " 'transformer_ae',\n",
              " 'diagonal_neural_gpu',\n",
              " 'xception',\n",
              " 'aligned',\n",
              " 'multi_model',\n",
              " 'neural_gpu',\n",
              " 'slice_net',\n",
              " 'byte_net',\n",
              " 'cycle_gan',\n",
              " 'transformer_sketch',\n",
              " 'blue_net']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "-H25oG91YQj3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "source": [
        "# Create your own model\n",
        "\n",
        "class MySimpleModel(t2t_model.T2TModel):\n",
        "\n",
        "  def model_fn_body(self, features):\n",
        "    inputs = features[\"inputs\"]\n",
        "    filters = self.hparams.hidden_size\n",
        "    h1 = tf.layers.conv2d(inputs, filters,\n",
        "                          kernel_size=(5, 5), strides=(2, 2))\n",
        "    h2 = tf.layers.conv2d(tf.nn.relu(h1), filters,\n",
        "                          kernel_size=(5, 5), strides=(2, 2))\n",
        "    return tf.layers.conv2d(tf.nn.relu(h2), filters,\n",
        "                            kernel_size=(3, 3))\n",
        "\n",
        "hparams = trainer_utils.create_hparams(\"basic_1\", data_dir)\n",
        "hparams.hidden_size = 64\n",
        "trainer_utils.add_problem_hparams(hparams, \"image_mnist\")\n",
        "model = MySimpleModel(hparams, Modes.TRAIN)"
      ],
      "cell_type": "code",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AWVd2I7PYz6H",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 12
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "19abcffa-6a56-4633-90c1-71a59a104ace",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1512165882231,
          "user_tz": 480,
          "elapsed": 105926,
          "user": {
            "displayName": "Ryan Sepassi",
            "photoUrl": "//lh4.googleusercontent.com/-dcHmhQy1Y2A/AAAAAAAAAAI/AAAAAAAABEw/if_k14yF4KI/s50-c-k-no/photo.jpg",
            "userId": "107877449274830904926"
          }
        }
      },
      "source": [
        "# Train\n",
        "\n",
        "# In Eager mode, opt.minimize must be passed a function that produces the loss\n",
        "def loss_function(features):\n",
        "  _, losses = model(features)\n",
        "  return losses[\"training\"]\n",
        "\n",
        "tfe_loss_fn = tfe.implicit_value_and_gradients(loss_function)\n",
        "optimizer = tf.train.AdamOptimizer()\n",
        "\n",
        "NUM_STEPS = 500\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# Repeat and batch the data\n",
        "mnist_train_dataset = mnist_problem.dataset(Modes.TRAIN, data_dir)\n",
        "mnist_train_dataset = mnist_train_dataset.repeat(None).batch(BATCH_SIZE)\n",
        "\n",
        "# Training loop\n",
        "for count, example in enumerate(tfe.Iterator(mnist_train_dataset)):\n",
        "  example[\"targets\"] = tf.reshape(example[\"targets\"], [BATCH_SIZE, 1, 1, 1])  # Make it 4D.\n",
        "  loss, gv = tfe_loss_fn(example)\n",
        "  optimizer.apply_gradients(gv)\n",
        "\n",
        "  if count % 50 == 0:\n",
        "    print(\"Step: %d, Loss: %.3f\" % (count, loss.numpy()))\n",
        "  if count >= NUM_STEPS:\n",
        "    break"
      ],
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reading data files from /content/t2t/data/image_mnist-train*\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/common_layers.py:1671: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
            "\n",
            "Step: 0, Loss: 5.430\n",
            "Step: 50, Loss: 0.833\n",
            "Step: 100, Loss: 0.722\n",
            "Step: 150, Loss: 0.529\n",
            "Step: 200, Loss: 0.349\n",
            "Step: 250, Loss: 0.293\n",
            "Step: 300, Loss: 0.303\n",
            "Step: 350, Loss: 0.295\n",
            "Step: 400, Loss: 0.275\n",
            "Step: 450, Loss: 0.290\n",
            "Step: 500, Loss: 0.334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CIFlkiVOd8jO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 2
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "70b92db9-9ec0-466c-e5c2-c5a39f13447d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1512165950748,
          "user_tz": 480,
          "elapsed": 2772,
          "user": {
            "displayName": "Ryan Sepassi",
            "photoUrl": "//lh4.googleusercontent.com/-dcHmhQy1Y2A/AAAAAAAAAAI/AAAAAAAABEw/if_k14yF4KI/s50-c-k-no/photo.jpg",
            "userId": "107877449274830904926"
          }
        }
      },
      "source": [
        "model.set_mode(Modes.EVAL)\n",
        "mnist_eval_dataset = mnist_problem.dataset(Modes.EVAL, data_dir)\n",
        "all_perplexities = []\n",
        "all_accuracies = []\n",
        "for count, example in enumerate(tfe.Iterator(mnist_eval_dataset)):\n",
        "  if count >= 100:\n",
        "    break\n",
        "\n",
        "  batch_inputs = tf.reshape(example[\"inputs\"], [1, 28, 28, 3])  # Make it 4D.\n",
        "  batch_targets = tf.reshape(example[\"targets\"], [1, 1, 1, 1])  # Make it 4D.\n",
        "  features = {\"inputs\": batch_inputs, \"targets\": batch_targets}\n",
        "\n",
        "  # Call the model.\n",
        "  predictions, _ = model(features)\n",
        "\n",
        "  # Calculate and append the metrics\n",
        "  all_perplexities.extend(metrics.padded_neg_log_perplexity(predictions, features[\"targets\"]))\n",
        "  all_accuracies.extend(metrics.padded_accuracy(predictions, features[\"targets\"]))\n",
        "\n",
        "# Print out metrics on the dataset\n",
        "print(\"Accuracy: %.2f\" % tf.reduce_mean(tf.concat(all_accuracies, axis=1)).numpy())"
      ],
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reading data files from /content/t2t/data/image_mnist-dev*\n",
            "Accuracy: 0.98\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}